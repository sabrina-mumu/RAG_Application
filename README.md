# ğŸ“š Multilingual RAG System for HSC26 Bangla 1st Paper (LangChain + Gemini + FAISS)

This project builds a simple **Retrieval-Augmented Generation (RAG)** system capable of answering **Bangla and English** queries from a scanned Bangla textbook. It combines **OCR, chunking, semantic search**, and **generative AI (Google Gemini)** to answer natural language questions about the textbook.

---

## ğŸ› ï¸ Setup Guide

### âœ… System Requirements (Colab/Linux)

```bash
sudo apt-get update
sudo apt-get install -y poppler-utils tesseract-ocr tesseract-ocr-ben
```

### âœ… Python Libraries

```bash
pip install langchain langchain_google_genai pytesseract pdf2image faiss-cpu sentence-transformers langdetect numpy
```

---

## ğŸ“„ Used Tools, Libraries & Packages

- **PDF to Image:** `pdf2image`
- **OCR Engine:** `Tesseract-OCR` (with Bangla support)
- **Text Embeddings:** `sentence-transformers` (multilingual model)
- **Similarity Search:** `FAISS`
- **RAG Framework:** `LangChain`
- **LLM:** `Google Gemini 1.5 Flash` via `langchain_google_genai`

---

## ğŸ“‚ Input

Upload the provided PDF:  
**`HSC26-Bangla1st-Paper.pdf`**

Only pages **3 to 19** are processed to avoid noise.

---

## ğŸ’¬ Sample Queries & Outputs

### âœ… Bangla Queries

| Query                                                | Answer                              |
|------------------------------------------------------|-------------------------------------|
| à¦…à¦¨à§à¦ªà¦®à§‡à¦° à¦­à¦¾à¦·à¦¾à¦¯à¦¼ à¦¸à§à¦ªà§à¦°à§à¦· à¦•à¦¾à¦•à§‡ à¦¬à¦²à¦¾ à¦¹à¦¯à¦¼à§‡à¦›à§‡?              | à¦‰à¦¤à§à¦¤à¦° à¦ªà¦¾à¦“à¦¯à¦¼à¦¾ à¦¯à¦¾à¦¯à¦¼à¦¨à¦¿ âŒ              |
| à¦•à¦¾à¦•à§‡ à¦…à¦¨à§à¦ªà¦®à§‡à¦° à¦­à¦¾à¦—à§à¦¯ à¦¦à§‡à¦¬à¦¤à¦¾ à¦¬à¦²à§‡ à¦‰à¦²à§à¦²à§‡à¦– à¦•à¦°à¦¾ à¦¹à¦¯à¦¼à§‡à¦›à§‡?       | à¦…à¦¨à§à¦ªà¦®à§‡à¦° à¦®à¦¾à¦®à¦¾à¦•à§‡... âœ…                |
| à¦¬à¦¿à¦¯à¦¼à§‡à¦° à¦¸à¦®à¦¯à¦¼ à¦•à¦²à§à¦¯à¦¾à¦£à§€à¦° à¦ªà§à¦°à¦•à§ƒà¦¤ à¦¬à¦¯à¦¼à¦¸ à¦•à¦¤ à¦›à¦¿à¦²?              | à¦‰à¦¤à§à¦¤à¦° à¦ªà¦¾à¦“à¦¯à¦¼à¦¾ à¦¯à¦¾à¦¯à¦¼à¦¨à¦¿ âŒ              |

### âœ… English Queries

| Query                                               | Answer                              |
|-----------------------------------------------------|-------------------------------------|
| Who is called the perfect man in Anupam's words?   | Anupam calls himself a "perfect man" âŒ |
| Who is referred to as Anupam's fate god?           | Answer not found âŒ                 |

### âœ… Accuracy: `1 / 5 = 20%`

---

## â“ Required Submission Questions

### ğŸ“Œ 1. What method or library did you use to extract the text, and why? Did you face any formatting challenges with the PDF content?

- **Used Tools:** `pdf2image` + `pytesseract` with `tesseract-ocr-ben`
- **Reason:** The textbook is a scanned image-based PDF. Tesseract supports Bangla OCR well, especially with the `tesseract-ocr-ben` package.
- **Challenges:** OCR from low-resolution scanned text led to:
  - Typos and artifacts
  - Sentence boundary confusion
  - Inconsistent spacing and alignment  
  These affected retrieval and answer accuracy.

---

### ğŸ“Œ 2. What chunking strategy did you choose? Why do you think it works well for semantic retrieval?

- **Strategy:** Sentence-based chunking with 2-sentence overlap
- **Reasoning:** In narrative/essay-style Bangla content, paragraph breaks are unreliable due to OCR errors. Sentence-level chunking maintains coherence while the overlap captures context for each chunk.

---

### ğŸ“Œ 3. What embedding model did you use? Why did you choose it? How does it capture the meaning of the text?

- **Model:** `sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2`
- **Why:** 
  - Supports over 50+ languages including Bangla and English
  - Efficient for Colab usage (small + accurate)
  - Captures sentence-level meaning and semantic closeness using transformer architecture
- **How:** It converts both document chunks and queries into dense vector representations that encode meaning beyond keyword matching.

---

### ğŸ“Œ 4. How are you comparing the query with your stored chunks? Why did you choose this similarity method and storage setup?

- **Comparison:** Cosine similarity between embedding vectors
- **Store:** `FAISS` vector database
- **Why:** 
  - Cosine similarity measures angular closeness of meanings
  - FAISS is optimized for fast and scalable dense vector search
- This allows quick retrieval of semantically similar text passages even with translation or paraphrasing.

---

### ğŸ“Œ 5. How do you ensure that the question and the document chunks are compared meaningfully? What would happen if the query is vague or missing context?

- **Mechanism:**
  - Both query and chunks are embedded using the same multilingual model
  - Overlapping chunks provide continuity
  - `langdetect` is used to detect the query language before passing it to the model
- **Limitations:**
  - If the query is vague, short, or ambiguous, retrieval becomes noisy
  - Missing context in OCRâ€™d text (due to typos or chunk breaks) causes further errors

---

### ğŸ“Œ 6. Do the results seem relevant? If not, what might improve them?

- **Performance:** `20% accuracy` on test set suggests partial success
- **Issues Identified:**
  - OCR noise â†’ missed key answers (e.g., â€œà¦¶à§à¦®à§à¦­à§à¦¨à¦¾à¦¥â€ not matched)
  - Embedding model may miss Bangla literary nuances
  - Chunking may cut off answers mid-sentence

#### âœ… Potential Improvements:

- Clean OCR output using language models or regex post-processing
- Use larger or fine-tuned embedding models for Bangla (e.g., `LaBSE`)
- Add context-aware reranker (e.g., Gemini â†’ rerank top-10 chunks)
- Use paragraph-based chunking with fallback to sentence-based when needed

---

## ğŸ“ Conclusion

This RAG system provides a simple but extensible framework for **Bangla question-answering** using open-source tools and Gemini LLMs. With better OCR cleaning and stronger embeddings, it can scale to many subjects and languages.

---

## ğŸ“Œ Authors

- Built by: **Sabrina Mostafij Mumu**
- Powered by: LangChain, Gemini, FAISS, Tesseract OCR
